import re
import ast
import time
import torch
import string
import numpy as np
import pandas as pd
from tqdm import tqdm
from transformers import BertModel, BertTokenizer
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from keras.models import Sequential
from keras.layers import Input, Bidirectional, LSTM, GlobalMaxPooling1D, Dense
from keras.utils import to_categorical
from keras.optimizers import RMSprop
import random
import tensorflow as tf

# Set TensorFlow to use only GPU
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')
        tf.config.experimental.set_memory_growth(gpus[0], True)
    except RuntimeError as e:
        print(e)

# Load the data
df = pd.read_csv("Ids_BERT_Younes_newdataset-dp.csv", encoding='utf-8')
df

def Convert_StrIds_To_ListIds(string_list):
    actual_list = ast.literal_eval(string_list)
    return actual_list

# Apply the function to the 'Tokens_Ids' column in the DataFrame
tqdm.pandas()  # Enable progress bar for pandas operations
df['Tokens_Ids'] = df['Tokens_Ids'].progress_apply(Convert_StrIds_To_ListIds)


# Load BERT model and tokenizer
model = BertModel.from_pretrained('bert-base-uncased').to('cuda')
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def Convert_IDs_To_Vector(input_ids):
    if not input_ids:
        print("Input_ids is empty.")
        return None
    
    input_ids = torch.tensor(input_ids).unsqueeze(0).to('cuda')
    with torch.no_grad():
        outputs = model(input_ids)
        embeddings = outputs.last_hidden_state[0].cpu().tolist()
    
    return embeddings

# Convert data in batches to avoid memory issues
batch_size = 5000  # You can adjust this batch size based on your memory capacity
tokens_vectors = []

for i in tqdm(range(0, len(df), batch_size)):
    batch_tokens = df['Tokens_Ids'].iloc[i:i+batch_size]
    batch_vectors = batch_tokens.progress_apply(Convert_IDs_To_Vector)
    tokens_vectors.extend(batch_vectors)

df['Tokens_vectors'] = tokens_vectors

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df['Tokens_vectors'], df['Class'], test_size=0.2, random_state=0)


# Label encoding
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# One-hot encoding of labels
num_classes = len(np.unique(y_train_encoded))
y_train_categorical = to_categorical(y_train_encoded, num_classes=num_classes)
y_test_categorical = to_categorical(y_test_encoded, num_classes=num_classes)

# Padding sequences
max_sequence_length = max(len(seq) for seq in X_train if seq is not None)
X_train_padded = pad_sequences([seq for seq in X_train if seq is not None], maxlen=max_sequence_length, padding='post', dtype='float32')
X_test_padded = pad_sequences([seq for seq in X_test if seq is not None], maxlen=max_sequence_length, padding='post', dtype='float32')


# Ensure that all numpy arrays are converted to tensors and moved to GPU
X_train_padded = tf.convert_to_tensor(X_train_padded, dtype=tf.float32)
X_test_padded = tf.convert_to_tensor(X_test_padded, dtype=tf.float32)
y_train_categorical = tf.convert_to_tensor(y_train_categorical, dtype=tf.float32)
y_test_categorical = tf.convert_to_tensor(y_test_categorical, dtype=tf.float32)


# Function to create and compile model
def create_model(num_neurons_layer1, num_neurons_layer2, learning_rate):
    model = Sequential()
    model.add(Input(shape=(X_train_padded.shape[1], X_train_padded.shape[2])))  # Input layer
    model.add(Bidirectional(LSTM(num_neurons_layer1, return_sequences=True)))  # BiLSTM layer
    model.add(GlobalMaxPooling1D())  # Global Max Pooling layer
    model.add(Dense(num_neurons_layer2, activation='relu'))  # Fully connected layer
    model.add(Dense(num_classes, activation='softmax'))  # Output layer
    
    optimizer = RMSprop(learning_rate=learning_rate)
    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    
    return model


# Function to perform random search
def random_search(num_trials=20):
    best_accuracy = 0
    best_params = None
    best_model = None
    
    for _ in range(num_trials):
        num_neurons_layer1 = random.randint(32, 256)
        num_neurons_layer2 = random.randint(32, 256)
        learning_rate = 10 ** random.uniform(-5, -1)
        
        model = create_model(num_neurons_layer1, num_neurons_layer2, learning_rate)
        
        try:
            history = model.fit(X_train_padded, y_train_categorical, epochs=10, batch_size=64, validation_data=(X_test_padded, y_test_categorical), verbose=0)
            
            loss, accuracy = model.evaluate(X_test_padded, y_test_categorical, verbose=0)
            
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_params = (num_neurons_layer1, num_neurons_layer2, learning_rate)
                best_model = model
        except tf.errors.ResourceExhaustedError:
            print("ResourceExhaustedError: Skipping this trial due to memory constraints.")
            continue
    
    return best_model, best_params

# Perform random search
best_model, best_params = random_search()

# Train the final model with best parameters
if best_params is not None:
    num_neurons_layer1, num_neurons_layer2, learning_rate = best_params
    final_model = create_model(num_neurons_layer1, num_neurons_layer2, learning_rate)
    final_history = final_model.fit(X_train_padded, y_train_categorical, epochs=50, batch_size=64, validation_data=(X_test_padded, y_test_categorical))

    # Evaluate the final model
    loss, accuracy = final_model.evaluate(X_test_padded, y_test_categorical)
    print("Test Accuracy:", accuracy)

    # Predict labels for test data
    y_pred = np.argmax(final_model.predict(X_test_padded), axis=-1)

    # Calculate precision, recall, and F1-score
    test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test_encoded, y_pred, average='macro')

    print("Test Precision:", test_precision)
    print("Test Recall:", test_recall)
    print("Test F1 Score:", test_f1)
else:
    print("Random search did not find any suitable parameters due to memory constraints.")

if best_params is not None:
    print(f"Best parameters found: num_neurons_layer1={best_params[0]}, num_neurons_layer2={best_params[1]}, learning_rate={best_params[2]}")
else:
    print("Random search did not find any suitable parameters due to memory constraints.")

# Predict labels for train data
y_pred_train = np.argmax(final_model.predict(X_train_padded), axis=-1)

# Calculate precision, recall, and F1-score for train data
train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(y_train_encoded, y_pred_train, average='macro')

print("Train Precision:", train_precision)
print("Train Recall:", train_recall)
print("Train F1 Score:", train_f1)

import matplotlib.pyplot as plt

# Plotting accuracy curves
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(final_history.history['accuracy'], label='Training Accuracy')
plt.plot(final_history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.xlim(0, 50)
plt.xticks(range(0, 51, 10))
plt.ylim(0, 1)
plt.yticks(np.arange(0, 1, 0.1))
plt.title('Training and Validation Accuracy BERT_BiLSTM')
plt.legend()

# Plotting loss curves
plt.subplot(1, 2, 2)
plt.plot(final_history.history['loss'], label='Training Loss')
#plt.plot(history.history['val_loss'], label='Validation Loss')
#plt.plot(negative_accuracy, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.xlim(0, 50)
plt.xticks(range(0, 51, 10))
#plt.ylim(0, 1.3)

plt.title('Training and Validation Loss')
plt.legend()

plt.show()
